Domain 2: CyberSecurity
Problem Statement 3:
AI-Generated Content and Deepfake Detection Platform

Description:
AI‑generated content and deepfakes are becoming increasingly realistic.
Ordinary users find it difficult to distinguish real content from manipulated
media. This fuels misinformation, scams, and erosion of trust online.
There is a strong need for tools that can assist in content verification. Such
systems should be accessible to non‑experts. Transparency and awareness
are critical.

Expected Solution:
Build a detection system that analyzes text, images, audio, or video for
AI‑generated patterns. The tool should provide a confidence score rather
than absolute claims. It should explain indicators in simple terms. The
solution should prioritize ethical and responsible usage.

Deliverable :
-A multi-modal analysis engine designed to detect AI patterns in text,
images, and audio/video files.
-A confidence-based results display that provides a percentage
likelihood of manipulation rather than an absolute binary claim.
-An "Indicator Breakdown" section that uses simple terms to explain visual or auditory artifacts typical of deepfakes.